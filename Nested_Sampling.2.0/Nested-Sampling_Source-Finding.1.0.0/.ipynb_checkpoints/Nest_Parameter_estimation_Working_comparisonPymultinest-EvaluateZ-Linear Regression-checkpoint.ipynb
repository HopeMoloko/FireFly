{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \" Keep it Simple Stupid!\"\n",
    "# \" Don't Repeat Yourself!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a good function:\n",
    "  \n",
    "       -Sensibly named\n",
    "      -Has a single responsibility\n",
    "      -Includes a docstring\n",
    "      -Returns a value\n",
    "      -Is not longer than 50 lines\n",
    "      -Is idempotent and, if possible , pure\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################Import Modules##########################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import corner\n",
    "import copy as Makecopy\n",
    "\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_function(params,x):\n",
    "    '''Return the model value given a,b,c, and x paramters'''\n",
    "    mu = 1\n",
    "    sigma = 1\n",
    "    a = params[0]\n",
    "    model_value = a*np.exp(-(x-mu)/2*sigma**2)\n",
    "    return model_value\n",
    "\n",
    "def Log_Likelihood(data=None,sigma=None,model=None):\n",
    "    \n",
    "    '''Return the Log-Likelihood.\n",
    "    lnLikelihood = sum(f(data|model,sigma^2))\n",
    "                =-(n/2)*ln(2*pi) - (n/2)*ln(sigma^2) - (1/2*sigma^2)*sum((data-model)^2)    \n",
    "    Keyword arguments:\n",
    "    sigma -- noise level\n",
    "    model    -- Model\n",
    "    data     -- The data'''\n",
    "    #Unit test for shape of data amd model\n",
    "    assert data.shape == model.shape\n",
    "    \n",
    "    \n",
    "    Term1 = -0.5*np.log(2*np.pi*(sigma**2))\n",
    "    Term2 = -0.5*(1/sigma**2)*(data-model)**2\n",
    "    \n",
    "    Log_Like = sum(Term1 + Term2)\n",
    "    \n",
    "    return Log_Like\n",
    "\n",
    "def prior_transform(u = None):\n",
    "    '''Return the transformed prior space,array.'''\n",
    "    \n",
    "    a = 15.0*u[0]\n",
    "    \n",
    "    return np.array([a])\n",
    "\n",
    "\n",
    "def log_plus(x,y):\n",
    "    '''Return the addition of x + y in log-space'''\n",
    "    \n",
    "    if x>y:\n",
    "        return x+np.log(1+np.exp(y-x))\n",
    "    \n",
    "    else:\n",
    "        return y+np.log(1+np.exp(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1000)\n",
    "\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of live points\n",
    "num_of_live_points = 200 \n",
    "\n",
    "#Number of dimensions\n",
    "ndim = 3\n",
    "\n",
    "#Save objects\n",
    "points = np.zeros((num_of_live_points,ndim))\n",
    "\n",
    "#log_likelihood of live objects\n",
    "log_like_of_live_points = np.zeros((num_of_live_points))\n",
    "\n",
    "\n",
    "#Generate Live objects\n",
    "for i in range(num_of_live_points):\n",
    "    points[i,:] = prior_transform(u=np.random.uniform(0,1.0,size=ndim))\n",
    "    model = Model_function(params=points[i,:],x=x_values)\n",
    "    log_like_of_live_points[i] = Log_Likelihood(data=y_values,sigma=error_values,model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest = 5000\n",
    "keep = np.zeros((nest,ndim))  #store bad points\n",
    "logl_sample = []     #Store Log-likelihood of samples\n",
    "X_sample = []        #Store prior mass\n",
    "   \n",
    "\n",
    "\n",
    "logWT = []  #Store  weight =width*likelihood\n",
    "\n",
    "\n",
    "logZ = -1e100     # SUM(weights)= Z Evidence\n",
    "H = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined intervals for each parameters\n",
    "Flat_interval = [(0,5),(0,2),(0,2)]\n",
    "mcmc_steps = 50\n",
    "Acceptance = np.empty((nest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN NS LOOP##\n",
    "\n",
    "#Outer interval \n",
    "logw = np.log(1.0 - np.exp(-1.0 / num_of_live_points))\n",
    "\n",
    "for i in range(nest):\n",
    "    # Draw worst object with L* from n points\n",
    "    worst = np.argmin(log_like_of_live_points)\n",
    "    \n",
    "    #Save worst opbject\n",
    "    keep[i,:] = points[worst,:]\n",
    "    logl_sample.append(log_like_of_live_points[worst])\n",
    "    \n",
    "    #Save prior mass\n",
    "    X_sample.append(logw)\n",
    "    \n",
    "    #Weight\n",
    "    logwt = logw + log_like_of_live_points[worst]\n",
    "    \n",
    "    \n",
    "    #Save weight\n",
    "    logWT.append(logwt)\n",
    "    \n",
    "    #Update Evidence Z\n",
    "    logZnew = log_plus(logZ,logwt)  \n",
    "    \n",
    "    #Update H information\n",
    "    H = np.exp(logwt-logZnew)*log_like_of_live_points[worst] \\\n",
    "    +np.exp(logZ-logZnew)*(H+logZ)-logZnew\n",
    "    \n",
    "    #Update logZ\n",
    "    logZ = logZnew\n",
    "    #Shrink interval\n",
    "    logw -= 1.0/num_of_live_points\n",
    "    \n",
    "\n",
    "    while True:#----copy a random point and do mcmc from there-----\n",
    "        copy = np.random.randint(len(points))\n",
    "        if (copy != worst):break\n",
    "            \n",
    "    points[worst,:] = Makecopy.deepcopy(points[copy,:])\n",
    "    log_Likelihood_old =  log_like_of_live_points[copy]\n",
    "    \n",
    "    theta = points[copy,:]\n",
    "    \n",
    "    #UNIT TEST check for correct shape\n",
    "    assert theta.shape == (ndim,)\n",
    "    \n",
    "   # initialize mcmc params\n",
    "    \n",
    "    scale = 1.0\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    for mcmci in range(mcmc_steps):  #Evolve within current worst likelihood L>L* , draw new point under constraint\n",
    "        \n",
    "        propose_step = np.random.normal(0,scale=scale,size=ndim)\n",
    "        new_point = theta + propose_step\n",
    "        \n",
    "        \n",
    "        add = 0\n",
    "        for j in range(len(theta)):\n",
    "                if Flat_interval[j][0] <= new_point[j] <= Flat_interval[j][1]:\n",
    "                    add += 1\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        if add == len(theta):\n",
    "            Prior = 1\n",
    "        else:\n",
    "            Prior = 0\n",
    "        \n",
    "        #Calculate Log_likelihood of new point\n",
    "        model = Model_function(params=new_point,x=x_values)\n",
    "        \n",
    "        #Ignore divde by zero runtimewarining\n",
    "        np.seterr(divide='ignore')\n",
    "        log_Likelihood_new = Log_Likelihood(data=y_values,sigma=error_values,model=model) + np.log(Prior)\n",
    "       \n",
    "    \n",
    "        #Acceptance ratio alpha\n",
    "        alpha = np.exp(log_Likelihood_new-log_Likelihood_old)\n",
    "        \n",
    "        \n",
    "        if alpha>=1:\n",
    "            points[worst,:] = new_point  #Replace worst point with new point\n",
    "            log_like_of_live_points[worst] = log_Likelihood_new   #Replace the worst likelihood with new one  \n",
    "            accept += 1\n",
    "            \n",
    "        else:\n",
    "            u = np.random.uniform()\n",
    "            if u <= alpha :\n",
    "                points[worst,:] = new_point \n",
    "                log_like_of_live_points[worst] = log_Likelihood_new\n",
    "                accept += 1\n",
    "                \n",
    "            else:\n",
    "                theta = theta\n",
    "                reject +=1\n",
    "                \n",
    "        #Changing the scale\n",
    "        if accept > reject:\n",
    "            scale *= np.exp(1./accept)\n",
    "        if accept < reject:\n",
    "            scale /= np.exp(1./reject)\n",
    "\n",
    "    \n",
    "    Acceptance_Ratio = accept/(accept+reject)\n",
    "    Acceptance[i] =  Acceptance_Ratio\n",
    "    \n",
    "                \n",
    "    if i >nest*np.exp(H)/np.log(2.):\n",
    "        break\n",
    "        \n",
    "\n",
    "Z = logZ\n",
    "Z_err = np.sqrt((H)/num_of_live_points)\n",
    "H = H        #np.exp(H)/np.log(2.)\n",
    "#print(\"Acceptance Ratio :\",Acceptance_Ratio)\n",
    "print('Evidence Z = {0} +-{1} : Information H = {2} '.format(Z,Z_err,H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(np.arange(0,len(Acceptance)),Acceptance,'+')\n",
    "plt.ylabel('Acceptance Ratio')\n",
    "plt.axhline(0.2,c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized samples\n",
    "wt = np.exp((logWT)-max(logWT))\n",
    "Weights = wt/sum(wt)\n",
    "\n",
    "#Effective sample size\n",
    "effective_sample_size = int(np.exp(-np.sum(Weights*np.log(Weights+1e-300))))\n",
    "S = 0\n",
    "sample = np.zeros((effective_sample_size,ndim))\n",
    "\n",
    "# Selecting the Effective sample\n",
    "while True:\n",
    "    rnd_point = np.random.randint(len(keep))\n",
    "    #proba = prob_weighted[rnd_point]/max(prob_weighted)\n",
    "    proba = Weights[rnd_point]/max(Weights)\n",
    "\n",
    "    if np.random.rand() < proba:\n",
    "        sample[S,:] = keep[rnd_point,:]\n",
    "        \n",
    "        S += 1\n",
    "    if S >= effective_sample_size:\n",
    "        break\n",
    "print('Effective Sample Size : {}'.format(effective_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "labels = ['a','b','c']\n",
    "for i in range(ndim):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(sample[:,i],histtype=\"step\",bins=20)\n",
    "    plt.xlabel(labels[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = np.mean(sample[:,0]),np.mean(sample[:,1]),np.mean(sample[:,2])\n",
    "y_model = a*x_values*np.sin(b*x_values + c)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x_values,y_model)\n",
    "plt.plot(x_values,y_values,'o',color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats from pymultinest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymultinest as py\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = py.Analyzer(n_params, outputfiles_basename = \"chains/chains-3-5000_1_\")\n",
    "stats = a.get_stats()\n",
    "bestfit_params = a.get_best_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pymultinest instance for marginal plots\n",
    "pyplot = py.plot.PlotMarginalModes(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "labels = ['a','b','c']\n",
    "for i in range(ndim):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    pyplot.plot_marginal(i)\n",
    "    plt.xlabel(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "pyplot.plot_modes_marginal(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = bestfit_params['parameters'][0],bestfit_params['parameters'][1],bestfit_params['parameters'][2]\n",
    "y_model_pynest = a*x_values*np.sin(b*x_values + c)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x_values,y_model_pynest)\n",
    "plt.plot(x_values,y_values,'o',color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
